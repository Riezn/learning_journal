{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "bQYO7-O-Myt2",
        "outputId": "9a0e9826-481e-4d84-b5fc-26e4001fac74"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PassengerId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Survived  Pclass  \\\n",
              "PassengerId                     \n",
              "1                   0       3   \n",
              "2                   1       1   \n",
              "3                   1       3   \n",
              "4                   1       1   \n",
              "5                   0       3   \n",
              "\n",
              "                                                          Name     Sex   Age  \\\n",
              "PassengerId                                                                    \n",
              "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
              "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
              "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
              "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
              "5                                     Allen, Mr. William Henry    male  35.0   \n",
              "\n",
              "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
              "PassengerId                                                          \n",
              "1                1      0         A/5 21171   7.2500   NaN        S  \n",
              "2                1      0          PC 17599  71.2833   C85        C  \n",
              "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
              "4                1      0            113803  53.1000  C123        S  \n",
              "5                0      0            373450   8.0500   NaN        S  "
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load data\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/afifai/pelatihan_machinelearning/master/data/train.csv\", index_col=0)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NMmFENQnNIAv"
      },
      "outputs": [],
      "source": [
        "df.drop(['Name', 'Ticket', 'Cabin', 'Embarked'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "X9y8CL7ZNN8m"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop('Survived', axis=1)\n",
        "y = df['Survived']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=46)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mgdWswOGNTda"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "\n",
        "num_col = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
        "cat_col = ['Sex']\n",
        "\n",
        "num_pipeline = make_pipeline(SimpleImputer(strategy='median'),\n",
        "                             StandardScaler())\n",
        "\n",
        "cat_pipeline = make_pipeline(OneHotEncoder())\n",
        "\n",
        "data_pipeline = ColumnTransformer([\n",
        "    ('pipe_num', num_pipeline, num_col),\n",
        "    ('pipe_cat', cat_pipeline, cat_col)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gOBDYiewNps4"
      },
      "outputs": [],
      "source": [
        "# extract feature using pipeline\n",
        "\n",
        "X_train_final = data_pipeline.fit_transform(X_train)\n",
        "X_test_final = data_pipeline.fit_transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmwmgRkcS-_M",
        "outputId": "d7090f93-04d8-4c2f-eafd-9b2d073089e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((712, 7), (179, 7))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_final.shape, X_test_final.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLpeVHg6gCnB"
      },
      "source": [
        "## Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QU5vDVFbUiIu",
        "outputId": "fa7c6546-40b1-46ec-83e6-d1c251d155f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7397 - accuracy: 0.5239 - val_loss: 0.7434 - val_accuracy: 0.5419\n",
            "Epoch 2/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.7219 - accuracy: 0.5955 - val_loss: 0.7245 - val_accuracy: 0.5978\n",
            "Epoch 3/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.7068 - accuracy: 0.6236 - val_loss: 0.7081 - val_accuracy: 0.6201\n",
            "Epoch 4/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.6503 - val_loss: 0.6924 - val_accuracy: 0.6369\n",
            "Epoch 5/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6810 - accuracy: 0.6657 - val_loss: 0.6799 - val_accuracy: 0.6592\n",
            "Epoch 6/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6691 - accuracy: 0.6896 - val_loss: 0.6674 - val_accuracy: 0.6760\n",
            "Epoch 7/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6580 - accuracy: 0.6994 - val_loss: 0.6556 - val_accuracy: 0.7039\n",
            "Epoch 8/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.7149 - val_loss: 0.6456 - val_accuracy: 0.7374\n",
            "Epoch 9/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6381 - accuracy: 0.7346 - val_loss: 0.6349 - val_accuracy: 0.7486\n",
            "Epoch 10/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6291 - accuracy: 0.7458 - val_loss: 0.6254 - val_accuracy: 0.7598\n",
            "Epoch 11/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6204 - accuracy: 0.7500 - val_loss: 0.6157 - val_accuracy: 0.7654\n",
            "Epoch 12/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6116 - accuracy: 0.7626 - val_loss: 0.6055 - val_accuracy: 0.7542\n",
            "Epoch 13/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6031 - accuracy: 0.7711 - val_loss: 0.5959 - val_accuracy: 0.7654\n",
            "Epoch 14/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5952 - accuracy: 0.7753 - val_loss: 0.5873 - val_accuracy: 0.7933\n",
            "Epoch 15/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.5880 - accuracy: 0.7809 - val_loss: 0.5787 - val_accuracy: 0.7989\n",
            "Epoch 16/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.5812 - accuracy: 0.7823 - val_loss: 0.5720 - val_accuracy: 0.7989\n",
            "Epoch 17/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5742 - accuracy: 0.7823 - val_loss: 0.5639 - val_accuracy: 0.8045\n",
            "Epoch 18/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.5674 - accuracy: 0.7837 - val_loss: 0.5564 - val_accuracy: 0.8101\n",
            "Epoch 19/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.7823 - val_loss: 0.5496 - val_accuracy: 0.8101\n",
            "Epoch 20/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.5541 - accuracy: 0.7935 - val_loss: 0.5429 - val_accuracy: 0.8156\n",
            "Epoch 21/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.5479 - accuracy: 0.7935 - val_loss: 0.5361 - val_accuracy: 0.8156\n",
            "Epoch 22/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.5415 - accuracy: 0.7935 - val_loss: 0.5301 - val_accuracy: 0.8212\n",
            "Epoch 23/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5356 - accuracy: 0.7963 - val_loss: 0.5246 - val_accuracy: 0.8268\n",
            "Epoch 24/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.8104 - val_loss: 0.5155 - val_accuracy: 0.8324\n",
            "Epoch 25/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.8118 - val_loss: 0.5055 - val_accuracy: 0.8324\n",
            "Epoch 26/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.5110 - accuracy: 0.8146 - val_loss: 0.4953 - val_accuracy: 0.8324\n",
            "Epoch 27/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.8076 - val_loss: 0.4849 - val_accuracy: 0.8324\n",
            "Epoch 28/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4939 - accuracy: 0.8132 - val_loss: 0.4761 - val_accuracy: 0.8324\n",
            "Epoch 29/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.8132 - val_loss: 0.4679 - val_accuracy: 0.8324\n",
            "Epoch 30/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4815 - accuracy: 0.8118 - val_loss: 0.4601 - val_accuracy: 0.8380\n",
            "Epoch 31/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.8104 - val_loss: 0.4548 - val_accuracy: 0.8324\n",
            "Epoch 32/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4726 - accuracy: 0.8118 - val_loss: 0.4496 - val_accuracy: 0.8324\n",
            "Epoch 33/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.8090 - val_loss: 0.4453 - val_accuracy: 0.8324\n",
            "Epoch 34/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.8090 - val_loss: 0.4413 - val_accuracy: 0.8324\n",
            "Epoch 35/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.8076 - val_loss: 0.4375 - val_accuracy: 0.8324\n",
            "Epoch 36/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4600 - accuracy: 0.8090 - val_loss: 0.4357 - val_accuracy: 0.8324\n",
            "Epoch 37/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.8090 - val_loss: 0.4332 - val_accuracy: 0.8324\n",
            "Epoch 38/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4561 - accuracy: 0.8090 - val_loss: 0.4306 - val_accuracy: 0.8324\n",
            "Epoch 39/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.8076 - val_loss: 0.4281 - val_accuracy: 0.8324\n",
            "Epoch 40/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4532 - accuracy: 0.8104 - val_loss: 0.4274 - val_accuracy: 0.8324\n",
            "Epoch 41/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4520 - accuracy: 0.8104 - val_loss: 0.4257 - val_accuracy: 0.8324\n",
            "Epoch 42/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4508 - accuracy: 0.8104 - val_loss: 0.4237 - val_accuracy: 0.8268\n",
            "Epoch 43/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4498 - accuracy: 0.8090 - val_loss: 0.4240 - val_accuracy: 0.8268\n",
            "Epoch 44/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4488 - accuracy: 0.8090 - val_loss: 0.4227 - val_accuracy: 0.8268\n",
            "Epoch 45/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.8090 - val_loss: 0.4214 - val_accuracy: 0.8268\n",
            "Epoch 46/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4469 - accuracy: 0.8062 - val_loss: 0.4200 - val_accuracy: 0.8268\n",
            "Epoch 47/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.8076 - val_loss: 0.4198 - val_accuracy: 0.8268\n",
            "Epoch 48/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4456 - accuracy: 0.8062 - val_loss: 0.4199 - val_accuracy: 0.8268\n",
            "Epoch 49/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.8062 - val_loss: 0.4197 - val_accuracy: 0.8268\n",
            "Epoch 50/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4440 - accuracy: 0.8076 - val_loss: 0.4186 - val_accuracy: 0.8268\n",
            "Epoch 51/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.8062 - val_loss: 0.4187 - val_accuracy: 0.8268\n",
            "Epoch 52/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4428 - accuracy: 0.8062 - val_loss: 0.4189 - val_accuracy: 0.8268\n",
            "Epoch 53/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4423 - accuracy: 0.8062 - val_loss: 0.4187 - val_accuracy: 0.8268\n",
            "Epoch 54/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.8090 - val_loss: 0.4196 - val_accuracy: 0.8268\n",
            "Epoch 55/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4412 - accuracy: 0.8090 - val_loss: 0.4199 - val_accuracy: 0.8212\n",
            "Epoch 56/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4408 - accuracy: 0.8090 - val_loss: 0.4192 - val_accuracy: 0.8212\n",
            "Epoch 57/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4403 - accuracy: 0.8062 - val_loss: 0.4192 - val_accuracy: 0.8212\n",
            "Epoch 58/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4399 - accuracy: 0.8076 - val_loss: 0.4191 - val_accuracy: 0.8212\n",
            "Epoch 59/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4395 - accuracy: 0.8076 - val_loss: 0.4185 - val_accuracy: 0.8212\n",
            "Epoch 60/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.8062 - val_loss: 0.4183 - val_accuracy: 0.8212\n",
            "Epoch 61/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.8076 - val_loss: 0.4183 - val_accuracy: 0.8268\n",
            "Epoch 62/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.8034 - val_loss: 0.4178 - val_accuracy: 0.8268\n",
            "Epoch 63/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4380 - accuracy: 0.8062 - val_loss: 0.4186 - val_accuracy: 0.8268\n",
            "Epoch 64/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4378 - accuracy: 0.8048 - val_loss: 0.4185 - val_accuracy: 0.8268\n",
            "Epoch 65/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.8048 - val_loss: 0.4177 - val_accuracy: 0.8268\n",
            "Epoch 66/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4370 - accuracy: 0.8048 - val_loss: 0.4176 - val_accuracy: 0.8268\n",
            "Epoch 67/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4367 - accuracy: 0.8048 - val_loss: 0.4173 - val_accuracy: 0.8268\n",
            "Epoch 68/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.8048 - val_loss: 0.4165 - val_accuracy: 0.8268\n",
            "Epoch 69/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4361 - accuracy: 0.8048 - val_loss: 0.4161 - val_accuracy: 0.8268\n",
            "Epoch 70/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4359 - accuracy: 0.8048 - val_loss: 0.4157 - val_accuracy: 0.8268\n",
            "Epoch 71/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4356 - accuracy: 0.8048 - val_loss: 0.4162 - val_accuracy: 0.8268\n",
            "Epoch 72/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4353 - accuracy: 0.8062 - val_loss: 0.4153 - val_accuracy: 0.8268\n",
            "Epoch 73/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.8048 - val_loss: 0.4163 - val_accuracy: 0.8268\n",
            "Epoch 74/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4349 - accuracy: 0.8048 - val_loss: 0.4164 - val_accuracy: 0.8268\n",
            "Epoch 75/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.8076 - val_loss: 0.4159 - val_accuracy: 0.8268\n",
            "Epoch 76/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4342 - accuracy: 0.8076 - val_loss: 0.4160 - val_accuracy: 0.8268\n",
            "Epoch 77/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.8090 - val_loss: 0.4152 - val_accuracy: 0.8268\n",
            "Epoch 78/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4337 - accuracy: 0.8090 - val_loss: 0.4151 - val_accuracy: 0.8268\n",
            "Epoch 79/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4337 - accuracy: 0.8076 - val_loss: 0.4160 - val_accuracy: 0.8268\n",
            "Epoch 80/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.8076 - val_loss: 0.4166 - val_accuracy: 0.8268\n",
            "Epoch 81/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.8062 - val_loss: 0.4140 - val_accuracy: 0.8212\n",
            "Epoch 82/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.8076 - val_loss: 0.4150 - val_accuracy: 0.8268\n",
            "Epoch 83/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.8076 - val_loss: 0.4161 - val_accuracy: 0.8268\n",
            "Epoch 84/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4322 - accuracy: 0.8090 - val_loss: 0.4157 - val_accuracy: 0.8268\n",
            "Epoch 85/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4319 - accuracy: 0.8090 - val_loss: 0.4162 - val_accuracy: 0.8212\n",
            "Epoch 86/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4319 - accuracy: 0.8090 - val_loss: 0.4158 - val_accuracy: 0.8212\n",
            "Epoch 87/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.8062 - val_loss: 0.4156 - val_accuracy: 0.8212\n",
            "Epoch 88/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4313 - accuracy: 0.8076 - val_loss: 0.4153 - val_accuracy: 0.8212\n",
            "Epoch 89/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4314 - accuracy: 0.8062 - val_loss: 0.4159 - val_accuracy: 0.8268\n",
            "Epoch 90/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4312 - accuracy: 0.8076 - val_loss: 0.4131 - val_accuracy: 0.8212\n",
            "Epoch 91/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.8076 - val_loss: 0.4134 - val_accuracy: 0.8268\n",
            "Epoch 92/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.8062 - val_loss: 0.4143 - val_accuracy: 0.8212\n",
            "Epoch 93/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4308 - accuracy: 0.8062 - val_loss: 0.4141 - val_accuracy: 0.8212\n",
            "Epoch 94/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.8048 - val_loss: 0.4149 - val_accuracy: 0.8212\n",
            "Epoch 95/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4303 - accuracy: 0.8090 - val_loss: 0.4157 - val_accuracy: 0.8324\n",
            "Epoch 96/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.8090 - val_loss: 0.4149 - val_accuracy: 0.8212\n",
            "Epoch 97/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4299 - accuracy: 0.8090 - val_loss: 0.4149 - val_accuracy: 0.8268\n",
            "Epoch 98/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.8118 - val_loss: 0.4150 - val_accuracy: 0.8268\n",
            "Epoch 99/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4297 - accuracy: 0.8076 - val_loss: 0.4142 - val_accuracy: 0.8268\n",
            "Epoch 100/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4294 - accuracy: 0.8104 - val_loss: 0.4143 - val_accuracy: 0.8268\n",
            "Epoch 101/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4293 - accuracy: 0.8090 - val_loss: 0.4144 - val_accuracy: 0.8268\n",
            "Epoch 102/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.8104 - val_loss: 0.4144 - val_accuracy: 0.8324\n",
            "Epoch 103/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4288 - accuracy: 0.8104 - val_loss: 0.4133 - val_accuracy: 0.8268\n",
            "Epoch 104/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.8104 - val_loss: 0.4135 - val_accuracy: 0.8268\n",
            "Epoch 105/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4286 - accuracy: 0.8104 - val_loss: 0.4148 - val_accuracy: 0.8380\n",
            "Epoch 106/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.8104 - val_loss: 0.4138 - val_accuracy: 0.8380\n",
            "Epoch 107/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.8118 - val_loss: 0.4143 - val_accuracy: 0.8268\n",
            "Epoch 108/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.8118 - val_loss: 0.4134 - val_accuracy: 0.8380\n",
            "Epoch 109/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.8104 - val_loss: 0.4135 - val_accuracy: 0.8380\n",
            "Epoch 110/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.8090 - val_loss: 0.4126 - val_accuracy: 0.8380\n",
            "Epoch 111/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.8090 - val_loss: 0.4138 - val_accuracy: 0.8324\n",
            "Epoch 112/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.8104 - val_loss: 0.4126 - val_accuracy: 0.8380\n",
            "Epoch 113/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4270 - accuracy: 0.8104 - val_loss: 0.4132 - val_accuracy: 0.8324\n",
            "Epoch 114/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8090 - val_loss: 0.4116 - val_accuracy: 0.8380\n",
            "Epoch 115/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4267 - accuracy: 0.8090 - val_loss: 0.4127 - val_accuracy: 0.8380\n",
            "Epoch 116/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4264 - accuracy: 0.8104 - val_loss: 0.4118 - val_accuracy: 0.8380\n",
            "Epoch 117/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4261 - accuracy: 0.8104 - val_loss: 0.4123 - val_accuracy: 0.8380\n",
            "Epoch 118/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4260 - accuracy: 0.8118 - val_loss: 0.4121 - val_accuracy: 0.8380\n",
            "Epoch 119/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4258 - accuracy: 0.8104 - val_loss: 0.4114 - val_accuracy: 0.8380\n",
            "Epoch 120/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4257 - accuracy: 0.8104 - val_loss: 0.4111 - val_accuracy: 0.8380\n",
            "Epoch 121/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4255 - accuracy: 0.8104 - val_loss: 0.4113 - val_accuracy: 0.8380\n",
            "Epoch 122/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4253 - accuracy: 0.8104 - val_loss: 0.4108 - val_accuracy: 0.8380\n",
            "Epoch 123/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4251 - accuracy: 0.8104 - val_loss: 0.4114 - val_accuracy: 0.8380\n",
            "Epoch 124/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.8146 - val_loss: 0.4117 - val_accuracy: 0.8380\n",
            "Epoch 125/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4248 - accuracy: 0.8132 - val_loss: 0.4119 - val_accuracy: 0.8324\n",
            "Epoch 126/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4246 - accuracy: 0.8104 - val_loss: 0.4111 - val_accuracy: 0.8268\n",
            "Epoch 127/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4245 - accuracy: 0.8132 - val_loss: 0.4122 - val_accuracy: 0.8324\n",
            "Epoch 128/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4243 - accuracy: 0.8132 - val_loss: 0.4113 - val_accuracy: 0.8324\n",
            "Epoch 129/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4240 - accuracy: 0.8132 - val_loss: 0.4108 - val_accuracy: 0.8324\n",
            "Epoch 130/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4239 - accuracy: 0.8132 - val_loss: 0.4110 - val_accuracy: 0.8324\n",
            "Epoch 131/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4237 - accuracy: 0.8132 - val_loss: 0.4110 - val_accuracy: 0.8324\n",
            "Epoch 132/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4234 - accuracy: 0.8132 - val_loss: 0.4114 - val_accuracy: 0.8324\n",
            "Epoch 133/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.8132 - val_loss: 0.4115 - val_accuracy: 0.8380\n",
            "Epoch 134/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4231 - accuracy: 0.8132 - val_loss: 0.4107 - val_accuracy: 0.8380\n",
            "Epoch 135/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4229 - accuracy: 0.8132 - val_loss: 0.4078 - val_accuracy: 0.8380\n",
            "Epoch 136/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4229 - accuracy: 0.8132 - val_loss: 0.4093 - val_accuracy: 0.8380\n",
            "Epoch 137/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.8132 - val_loss: 0.4098 - val_accuracy: 0.8324\n",
            "Epoch 138/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4225 - accuracy: 0.8118 - val_loss: 0.4108 - val_accuracy: 0.8324\n",
            "Epoch 139/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4221 - accuracy: 0.8132 - val_loss: 0.4096 - val_accuracy: 0.8324\n",
            "Epoch 140/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.8132 - val_loss: 0.4091 - val_accuracy: 0.8324\n",
            "Epoch 141/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4219 - accuracy: 0.8132 - val_loss: 0.4090 - val_accuracy: 0.8324\n",
            "Epoch 142/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.8132 - val_loss: 0.4091 - val_accuracy: 0.8268\n",
            "Epoch 143/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4216 - accuracy: 0.8132 - val_loss: 0.4080 - val_accuracy: 0.8324\n",
            "Epoch 144/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.8160 - val_loss: 0.4086 - val_accuracy: 0.8324\n",
            "Epoch 145/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4212 - accuracy: 0.8146 - val_loss: 0.4089 - val_accuracy: 0.8324\n",
            "Epoch 146/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4210 - accuracy: 0.8146 - val_loss: 0.4087 - val_accuracy: 0.8380\n",
            "Epoch 147/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4209 - accuracy: 0.8160 - val_loss: 0.4077 - val_accuracy: 0.8324\n",
            "Epoch 148/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.8160 - val_loss: 0.4065 - val_accuracy: 0.8324\n",
            "Epoch 149/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4206 - accuracy: 0.8146 - val_loss: 0.4084 - val_accuracy: 0.8268\n",
            "Epoch 150/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.8146 - val_loss: 0.4073 - val_accuracy: 0.8324\n",
            "Epoch 151/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4201 - accuracy: 0.8174 - val_loss: 0.4073 - val_accuracy: 0.8324\n",
            "Epoch 152/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.8160 - val_loss: 0.4067 - val_accuracy: 0.8212\n",
            "Epoch 153/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4198 - accuracy: 0.8132 - val_loss: 0.4066 - val_accuracy: 0.8268\n",
            "Epoch 154/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.8146 - val_loss: 0.4062 - val_accuracy: 0.8212\n",
            "Epoch 155/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4196 - accuracy: 0.8146 - val_loss: 0.4057 - val_accuracy: 0.8268\n",
            "Epoch 156/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.8146 - val_loss: 0.4075 - val_accuracy: 0.8324\n",
            "Epoch 157/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4192 - accuracy: 0.8132 - val_loss: 0.4067 - val_accuracy: 0.8268\n",
            "Epoch 158/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8132 - val_loss: 0.4069 - val_accuracy: 0.8268\n",
            "Epoch 159/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4188 - accuracy: 0.8132 - val_loss: 0.4060 - val_accuracy: 0.8268\n",
            "Epoch 160/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4188 - accuracy: 0.8132 - val_loss: 0.4069 - val_accuracy: 0.8324\n",
            "Epoch 161/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8132 - val_loss: 0.4078 - val_accuracy: 0.8324\n",
            "Epoch 162/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.8146 - val_loss: 0.4062 - val_accuracy: 0.8380\n",
            "Epoch 163/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4183 - accuracy: 0.8160 - val_loss: 0.4053 - val_accuracy: 0.8380\n",
            "Epoch 164/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4181 - accuracy: 0.8160 - val_loss: 0.4053 - val_accuracy: 0.8380\n",
            "Epoch 165/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4181 - accuracy: 0.8160 - val_loss: 0.4060 - val_accuracy: 0.8380\n",
            "Epoch 166/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8146 - val_loss: 0.4052 - val_accuracy: 0.8380\n",
            "Epoch 167/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4176 - accuracy: 0.8146 - val_loss: 0.4050 - val_accuracy: 0.8324\n",
            "Epoch 168/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4176 - accuracy: 0.8146 - val_loss: 0.4047 - val_accuracy: 0.8324\n",
            "Epoch 169/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8146 - val_loss: 0.4051 - val_accuracy: 0.8380\n",
            "Epoch 170/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4173 - accuracy: 0.8174 - val_loss: 0.4045 - val_accuracy: 0.8380\n",
            "Epoch 171/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4173 - accuracy: 0.8188 - val_loss: 0.4034 - val_accuracy: 0.8380\n",
            "Epoch 172/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.8160 - val_loss: 0.4042 - val_accuracy: 0.8380\n",
            "Epoch 173/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4170 - accuracy: 0.8160 - val_loss: 0.4040 - val_accuracy: 0.8380\n",
            "Epoch 174/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.8174 - val_loss: 0.4035 - val_accuracy: 0.8380\n",
            "Epoch 175/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4169 - accuracy: 0.8146 - val_loss: 0.4046 - val_accuracy: 0.8436\n",
            "Epoch 176/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4171 - accuracy: 0.8146 - val_loss: 0.4041 - val_accuracy: 0.8324\n",
            "Epoch 177/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4169 - accuracy: 0.8132 - val_loss: 0.4031 - val_accuracy: 0.8268\n",
            "Epoch 178/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4165 - accuracy: 0.8146 - val_loss: 0.4031 - val_accuracy: 0.8380\n",
            "Epoch 179/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.8174 - val_loss: 0.4037 - val_accuracy: 0.8380\n",
            "Epoch 180/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.8160 - val_loss: 0.4025 - val_accuracy: 0.8380\n",
            "Epoch 181/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8188 - val_loss: 0.4018 - val_accuracy: 0.8380\n",
            "Epoch 182/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4161 - accuracy: 0.8188 - val_loss: 0.4016 - val_accuracy: 0.8436\n",
            "Epoch 183/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4160 - accuracy: 0.8216 - val_loss: 0.4019 - val_accuracy: 0.8380\n",
            "Epoch 184/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4159 - accuracy: 0.8230 - val_loss: 0.4020 - val_accuracy: 0.8380\n",
            "Epoch 185/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4160 - accuracy: 0.8202 - val_loss: 0.4027 - val_accuracy: 0.8436\n",
            "Epoch 186/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4155 - accuracy: 0.8202 - val_loss: 0.4019 - val_accuracy: 0.8436\n",
            "Epoch 187/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4155 - accuracy: 0.8202 - val_loss: 0.4015 - val_accuracy: 0.8380\n",
            "Epoch 188/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4154 - accuracy: 0.8202 - val_loss: 0.4013 - val_accuracy: 0.8380\n",
            "Epoch 189/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.8216 - val_loss: 0.4003 - val_accuracy: 0.8380\n",
            "Epoch 190/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4151 - accuracy: 0.8202 - val_loss: 0.4011 - val_accuracy: 0.8380\n",
            "Epoch 191/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.8202 - val_loss: 0.4012 - val_accuracy: 0.8436\n",
            "Epoch 192/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4150 - accuracy: 0.8216 - val_loss: 0.4000 - val_accuracy: 0.8380\n",
            "Epoch 193/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.8188 - val_loss: 0.4007 - val_accuracy: 0.8380\n",
            "Epoch 194/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4147 - accuracy: 0.8202 - val_loss: 0.4003 - val_accuracy: 0.8436\n",
            "Epoch 195/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4149 - accuracy: 0.8216 - val_loss: 0.4011 - val_accuracy: 0.8436\n",
            "Epoch 196/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8216 - val_loss: 0.3992 - val_accuracy: 0.8380\n",
            "Epoch 197/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4145 - accuracy: 0.8216 - val_loss: 0.3990 - val_accuracy: 0.8380\n",
            "Epoch 198/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.8216 - val_loss: 0.3985 - val_accuracy: 0.8380\n",
            "Epoch 199/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4144 - accuracy: 0.8216 - val_loss: 0.3986 - val_accuracy: 0.8380\n",
            "Epoch 200/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4140 - accuracy: 0.8216 - val_loss: 0.3981 - val_accuracy: 0.8380\n",
            "Epoch 201/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4141 - accuracy: 0.8216 - val_loss: 0.3975 - val_accuracy: 0.8380\n",
            "Epoch 202/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.8202 - val_loss: 0.3994 - val_accuracy: 0.8380\n",
            "Epoch 203/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4138 - accuracy: 0.8202 - val_loss: 0.3983 - val_accuracy: 0.8380\n",
            "Epoch 204/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.8244 - val_loss: 0.3988 - val_accuracy: 0.8380\n",
            "Epoch 205/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.8230 - val_loss: 0.3989 - val_accuracy: 0.8380\n",
            "Epoch 206/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4134 - accuracy: 0.8230 - val_loss: 0.3987 - val_accuracy: 0.8380\n",
            "Epoch 207/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4134 - accuracy: 0.8244 - val_loss: 0.3989 - val_accuracy: 0.8380\n",
            "Epoch 208/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.8244 - val_loss: 0.3993 - val_accuracy: 0.8380\n",
            "Epoch 209/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4132 - accuracy: 0.8244 - val_loss: 0.3999 - val_accuracy: 0.8380\n",
            "Epoch 210/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8258 - val_loss: 0.3994 - val_accuracy: 0.8380\n",
            "Epoch 211/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4128 - accuracy: 0.8272 - val_loss: 0.4002 - val_accuracy: 0.8380\n",
            "Epoch 212/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.8258 - val_loss: 0.3998 - val_accuracy: 0.8380\n",
            "Epoch 213/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4126 - accuracy: 0.8244 - val_loss: 0.3969 - val_accuracy: 0.8380\n",
            "Epoch 214/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.8244 - val_loss: 0.3972 - val_accuracy: 0.8380\n",
            "Epoch 215/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4127 - accuracy: 0.8244 - val_loss: 0.3973 - val_accuracy: 0.8380\n",
            "Epoch 216/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4125 - accuracy: 0.8244 - val_loss: 0.3970 - val_accuracy: 0.8380\n",
            "Epoch 217/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4127 - accuracy: 0.8244 - val_loss: 0.3974 - val_accuracy: 0.8436\n",
            "Epoch 218/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.8258 - val_loss: 0.3982 - val_accuracy: 0.8492\n",
            "Epoch 219/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4124 - accuracy: 0.8230 - val_loss: 0.3978 - val_accuracy: 0.8492\n",
            "Epoch 220/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8230 - val_loss: 0.3970 - val_accuracy: 0.8380\n",
            "Epoch 221/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4120 - accuracy: 0.8230 - val_loss: 0.3972 - val_accuracy: 0.8380\n",
            "Epoch 222/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8230 - val_loss: 0.3966 - val_accuracy: 0.8380\n",
            "Epoch 223/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4120 - accuracy: 0.8230 - val_loss: 0.3967 - val_accuracy: 0.8380\n",
            "Epoch 224/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4121 - accuracy: 0.8244 - val_loss: 0.3975 - val_accuracy: 0.8380\n",
            "Epoch 225/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4118 - accuracy: 0.8244 - val_loss: 0.3969 - val_accuracy: 0.8380\n",
            "Epoch 226/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8258 - val_loss: 0.3971 - val_accuracy: 0.8492\n",
            "Epoch 227/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8272 - val_loss: 0.3960 - val_accuracy: 0.8436\n",
            "Epoch 228/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4117 - accuracy: 0.8258 - val_loss: 0.3973 - val_accuracy: 0.8380\n",
            "Epoch 229/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.8258 - val_loss: 0.3963 - val_accuracy: 0.8436\n",
            "Epoch 230/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.8272 - val_loss: 0.3957 - val_accuracy: 0.8436\n",
            "Epoch 231/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4114 - accuracy: 0.8258 - val_loss: 0.3960 - val_accuracy: 0.8436\n",
            "Epoch 232/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4114 - accuracy: 0.8258 - val_loss: 0.3957 - val_accuracy: 0.8436\n",
            "Epoch 233/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.8230 - val_loss: 0.3967 - val_accuracy: 0.8492\n",
            "Epoch 234/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4112 - accuracy: 0.8230 - val_loss: 0.3967 - val_accuracy: 0.8436\n",
            "Epoch 235/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.8244 - val_loss: 0.3959 - val_accuracy: 0.8436\n",
            "Epoch 236/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8244 - val_loss: 0.3963 - val_accuracy: 0.8436\n",
            "Epoch 237/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4112 - accuracy: 0.8258 - val_loss: 0.3957 - val_accuracy: 0.8492\n",
            "Epoch 238/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4109 - accuracy: 0.8272 - val_loss: 0.3961 - val_accuracy: 0.8436\n",
            "Epoch 239/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8287 - val_loss: 0.3962 - val_accuracy: 0.8492\n",
            "Epoch 240/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4109 - accuracy: 0.8287 - val_loss: 0.3957 - val_accuracy: 0.8547\n",
            "Epoch 241/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8272 - val_loss: 0.3952 - val_accuracy: 0.8547\n",
            "Epoch 242/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4109 - accuracy: 0.8272 - val_loss: 0.3968 - val_accuracy: 0.8603\n",
            "Epoch 243/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4105 - accuracy: 0.8272 - val_loss: 0.3958 - val_accuracy: 0.8547\n",
            "Epoch 244/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4106 - accuracy: 0.8287 - val_loss: 0.3958 - val_accuracy: 0.8547\n",
            "Epoch 245/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.8287 - val_loss: 0.3962 - val_accuracy: 0.8547\n",
            "Epoch 246/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.8287 - val_loss: 0.3952 - val_accuracy: 0.8492\n",
            "Epoch 247/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4105 - accuracy: 0.8301 - val_loss: 0.3958 - val_accuracy: 0.8492\n",
            "Epoch 248/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4103 - accuracy: 0.8301 - val_loss: 0.3954 - val_accuracy: 0.8492\n",
            "Epoch 249/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.8301 - val_loss: 0.3962 - val_accuracy: 0.8492\n",
            "Epoch 250/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4105 - accuracy: 0.8301 - val_loss: 0.3956 - val_accuracy: 0.8492\n",
            "Epoch 251/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.8301 - val_loss: 0.3965 - val_accuracy: 0.8547\n",
            "Epoch 252/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4101 - accuracy: 0.8287 - val_loss: 0.3957 - val_accuracy: 0.8547\n",
            "Epoch 253/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.8301 - val_loss: 0.3959 - val_accuracy: 0.8547\n",
            "Epoch 254/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4097 - accuracy: 0.8315 - val_loss: 0.3939 - val_accuracy: 0.8492\n",
            "Epoch 255/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.8301 - val_loss: 0.3935 - val_accuracy: 0.8492\n",
            "Epoch 256/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4104 - accuracy: 0.8301 - val_loss: 0.3936 - val_accuracy: 0.8492\n",
            "Epoch 257/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8301 - val_loss: 0.3934 - val_accuracy: 0.8492\n",
            "Epoch 258/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4097 - accuracy: 0.8301 - val_loss: 0.3938 - val_accuracy: 0.8492\n",
            "Epoch 259/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8301 - val_loss: 0.3948 - val_accuracy: 0.8492\n",
            "Epoch 260/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4096 - accuracy: 0.8329 - val_loss: 0.3948 - val_accuracy: 0.8492\n",
            "Epoch 261/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4095 - accuracy: 0.8301 - val_loss: 0.3951 - val_accuracy: 0.8547\n",
            "Epoch 262/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4095 - accuracy: 0.8329 - val_loss: 0.3950 - val_accuracy: 0.8492\n",
            "Epoch 263/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8315 - val_loss: 0.3944 - val_accuracy: 0.8492\n",
            "Epoch 264/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4092 - accuracy: 0.8315 - val_loss: 0.3940 - val_accuracy: 0.8492\n",
            "Epoch 265/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4092 - accuracy: 0.8301 - val_loss: 0.3936 - val_accuracy: 0.8492\n",
            "Epoch 266/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4092 - accuracy: 0.8329 - val_loss: 0.3932 - val_accuracy: 0.8492\n",
            "Epoch 267/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.8315 - val_loss: 0.3954 - val_accuracy: 0.8547\n",
            "Epoch 268/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4089 - accuracy: 0.8301 - val_loss: 0.3944 - val_accuracy: 0.8547\n",
            "Epoch 269/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8315 - val_loss: 0.3945 - val_accuracy: 0.8547\n",
            "Epoch 270/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4087 - accuracy: 0.8315 - val_loss: 0.3935 - val_accuracy: 0.8492\n",
            "Epoch 271/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4089 - accuracy: 0.8329 - val_loss: 0.3941 - val_accuracy: 0.8492\n",
            "Epoch 272/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4085 - accuracy: 0.8329 - val_loss: 0.3940 - val_accuracy: 0.8492\n",
            "Epoch 273/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4084 - accuracy: 0.8343 - val_loss: 0.3929 - val_accuracy: 0.8492\n",
            "Epoch 274/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8343 - val_loss: 0.3935 - val_accuracy: 0.8492\n",
            "Epoch 275/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8315 - val_loss: 0.3950 - val_accuracy: 0.8547\n",
            "Epoch 276/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4080 - accuracy: 0.8315 - val_loss: 0.3936 - val_accuracy: 0.8492\n",
            "Epoch 277/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8357 - val_loss: 0.3937 - val_accuracy: 0.8492\n",
            "Epoch 278/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4079 - accuracy: 0.8343 - val_loss: 0.3940 - val_accuracy: 0.8492\n",
            "Epoch 279/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.8329 - val_loss: 0.3954 - val_accuracy: 0.8492\n",
            "Epoch 280/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4079 - accuracy: 0.8301 - val_loss: 0.3944 - val_accuracy: 0.8492\n",
            "Epoch 281/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.8301 - val_loss: 0.3940 - val_accuracy: 0.8547\n",
            "Epoch 282/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4074 - accuracy: 0.8287 - val_loss: 0.3930 - val_accuracy: 0.8547\n",
            "Epoch 283/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.8272 - val_loss: 0.3934 - val_accuracy: 0.8547\n",
            "Epoch 284/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4073 - accuracy: 0.8329 - val_loss: 0.3934 - val_accuracy: 0.8547\n",
            "Epoch 285/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.8301 - val_loss: 0.3931 - val_accuracy: 0.8492\n",
            "Epoch 286/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4072 - accuracy: 0.8315 - val_loss: 0.3943 - val_accuracy: 0.8547\n",
            "Epoch 287/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8301 - val_loss: 0.3944 - val_accuracy: 0.8547\n",
            "Epoch 288/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.8301 - val_loss: 0.3946 - val_accuracy: 0.8492\n",
            "Epoch 289/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8329 - val_loss: 0.3947 - val_accuracy: 0.8547\n",
            "Epoch 290/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4066 - accuracy: 0.8329 - val_loss: 0.3946 - val_accuracy: 0.8492\n",
            "Epoch 291/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4065 - accuracy: 0.8329 - val_loss: 0.3948 - val_accuracy: 0.8547\n",
            "Epoch 292/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4065 - accuracy: 0.8315 - val_loss: 0.3940 - val_accuracy: 0.8547\n",
            "Epoch 293/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4064 - accuracy: 0.8301 - val_loss: 0.3938 - val_accuracy: 0.8492\n",
            "Epoch 294/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4064 - accuracy: 0.8301 - val_loss: 0.3933 - val_accuracy: 0.8492\n",
            "Epoch 295/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4063 - accuracy: 0.8329 - val_loss: 0.3940 - val_accuracy: 0.8492\n",
            "Epoch 296/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4062 - accuracy: 0.8315 - val_loss: 0.3937 - val_accuracy: 0.8547\n",
            "Epoch 297/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4061 - accuracy: 0.8315 - val_loss: 0.3936 - val_accuracy: 0.8547\n",
            "Epoch 298/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4059 - accuracy: 0.8315 - val_loss: 0.3938 - val_accuracy: 0.8492\n",
            "Epoch 299/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 0.8371 - val_loss: 0.3927 - val_accuracy: 0.8492\n",
            "Epoch 300/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4056 - accuracy: 0.8329 - val_loss: 0.3938 - val_accuracy: 0.8547\n"
          ]
        }
      ],
      "source": [
        "#import lib\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "#model\n",
        "model = Sequential()\n",
        "model.add(Dense(4, activation='relu', input_shape=(7,))) #input_shape hanya di hidden layer pertama setelah input layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "#compile\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#train\n",
        "history = model.fit(X_train_final, y_train, epochs=300, validation_data=(X_test_final, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OMIzNo6oY_B5",
        "outputId": "50c321c1-c242-4c69-a8f6-2565883685a4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.739709</td>\n",
              "      <td>0.523876</td>\n",
              "      <td>0.743433</td>\n",
              "      <td>0.541899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.721922</td>\n",
              "      <td>0.595506</td>\n",
              "      <td>0.724471</td>\n",
              "      <td>0.597765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.706768</td>\n",
              "      <td>0.623595</td>\n",
              "      <td>0.708061</td>\n",
              "      <td>0.620112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.693403</td>\n",
              "      <td>0.650281</td>\n",
              "      <td>0.692354</td>\n",
              "      <td>0.636872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.680957</td>\n",
              "      <td>0.665730</td>\n",
              "      <td>0.679861</td>\n",
              "      <td>0.659218</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       loss  accuracy  val_loss  val_accuracy\n",
              "0  0.739709  0.523876  0.743433      0.541899\n",
              "1  0.721922  0.595506  0.724471      0.597765\n",
              "2  0.706768  0.623595  0.708061      0.620112\n",
              "3  0.693403  0.650281  0.692354      0.636872\n",
              "4  0.680957  0.665730  0.679861      0.659218"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "metrics = pd.DataFrame(history.history)\n",
        "metrics.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "DUGcY1vFZaAL",
        "outputId": "74c56894-a6a2-4d8b-dec2-7e0d487d99ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "metrics[['loss','val_loss']].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUCuixPdfFIt",
        "outputId": "7c2bb4c3-5f53-4395-bce1-928d06458037"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 4)                 32        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 37\n",
            "Trainable params: 37\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "imJhksLsfx_Y",
        "outputId": "bb595a78-68e1-44d5-a07f-66cc93e0d5da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADPop69BgHol"
      },
      "source": [
        "## Functional API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PQ3H47MwhLoj",
        "outputId": "56ad334f-04e0-4323-9550-b759d67496ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 7)]               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4)                 32        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 37\n",
            "Trainable params: 37\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/300\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9590 - accuracy: 0.4733 - val_loss: 0.8517 - val_accuracy: 0.4693\n",
            "Epoch 2/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.8893 - accuracy: 0.4860 - val_loss: 0.7937 - val_accuracy: 0.4860\n",
            "Epoch 3/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.8282 - accuracy: 0.5225 - val_loss: 0.7419 - val_accuracy: 0.5866\n",
            "Epoch 4/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.7721 - accuracy: 0.5829 - val_loss: 0.6984 - val_accuracy: 0.6034\n",
            "Epoch 5/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.7247 - accuracy: 0.6053 - val_loss: 0.6588 - val_accuracy: 0.6369\n",
            "Epoch 6/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6833 - accuracy: 0.6222 - val_loss: 0.6263 - val_accuracy: 0.6592\n",
            "Epoch 7/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.6713 - val_loss: 0.5999 - val_accuracy: 0.7095\n",
            "Epoch 8/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.6192 - accuracy: 0.6854 - val_loss: 0.5779 - val_accuracy: 0.7430\n",
            "Epoch 9/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.5961 - accuracy: 0.7121 - val_loss: 0.5606 - val_accuracy: 0.7542\n",
            "Epoch 10/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5774 - accuracy: 0.7191 - val_loss: 0.5464 - val_accuracy: 0.7709\n",
            "Epoch 11/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.5610 - accuracy: 0.7317 - val_loss: 0.5350 - val_accuracy: 0.7765\n",
            "Epoch 12/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.5484 - accuracy: 0.7360 - val_loss: 0.5255 - val_accuracy: 0.7877\n",
            "Epoch 13/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.5379 - accuracy: 0.7430 - val_loss: 0.5179 - val_accuracy: 0.7765\n",
            "Epoch 14/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.5288 - accuracy: 0.7514 - val_loss: 0.5108 - val_accuracy: 0.7821\n",
            "Epoch 15/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.5217 - accuracy: 0.7612 - val_loss: 0.5045 - val_accuracy: 0.7821\n",
            "Epoch 16/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.5148 - accuracy: 0.7683 - val_loss: 0.4993 - val_accuracy: 0.7877\n",
            "Epoch 17/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.5088 - accuracy: 0.7683 - val_loss: 0.4948 - val_accuracy: 0.7933\n",
            "Epoch 18/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.5037 - accuracy: 0.7640 - val_loss: 0.4902 - val_accuracy: 0.7989\n",
            "Epoch 19/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4992 - accuracy: 0.7697 - val_loss: 0.4866 - val_accuracy: 0.8101\n",
            "Epoch 20/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4951 - accuracy: 0.7767 - val_loss: 0.4829 - val_accuracy: 0.7989\n",
            "Epoch 21/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4914 - accuracy: 0.7809 - val_loss: 0.4796 - val_accuracy: 0.8045\n",
            "Epoch 22/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.7851 - val_loss: 0.4770 - val_accuracy: 0.7989\n",
            "Epoch 23/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4850 - accuracy: 0.7851 - val_loss: 0.4744 - val_accuracy: 0.7989\n",
            "Epoch 24/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4823 - accuracy: 0.7809 - val_loss: 0.4703 - val_accuracy: 0.8045\n",
            "Epoch 25/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4794 - accuracy: 0.7823 - val_loss: 0.4677 - val_accuracy: 0.8045\n",
            "Epoch 26/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7795 - val_loss: 0.4654 - val_accuracy: 0.8045\n",
            "Epoch 27/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7795 - val_loss: 0.4634 - val_accuracy: 0.8101\n",
            "Epoch 28/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4728 - accuracy: 0.7879 - val_loss: 0.4611 - val_accuracy: 0.8101\n",
            "Epoch 29/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4711 - accuracy: 0.7963 - val_loss: 0.4592 - val_accuracy: 0.8101\n",
            "Epoch 30/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4695 - accuracy: 0.7978 - val_loss: 0.4578 - val_accuracy: 0.8268\n",
            "Epoch 31/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4677 - accuracy: 0.7949 - val_loss: 0.4559 - val_accuracy: 0.8268\n",
            "Epoch 32/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4662 - accuracy: 0.7963 - val_loss: 0.4542 - val_accuracy: 0.8268\n",
            "Epoch 33/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4650 - accuracy: 0.7935 - val_loss: 0.4525 - val_accuracy: 0.8268\n",
            "Epoch 34/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4638 - accuracy: 0.7907 - val_loss: 0.4510 - val_accuracy: 0.8268\n",
            "Epoch 35/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.7893 - val_loss: 0.4503 - val_accuracy: 0.8268\n",
            "Epoch 36/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4621 - accuracy: 0.7893 - val_loss: 0.4497 - val_accuracy: 0.8268\n",
            "Epoch 37/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7879 - val_loss: 0.4490 - val_accuracy: 0.8268\n",
            "Epoch 38/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7879 - val_loss: 0.4473 - val_accuracy: 0.8268\n",
            "Epoch 39/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4597 - accuracy: 0.7879 - val_loss: 0.4469 - val_accuracy: 0.8268\n",
            "Epoch 40/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.7851 - val_loss: 0.4462 - val_accuracy: 0.8268\n",
            "Epoch 41/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4582 - accuracy: 0.7865 - val_loss: 0.4449 - val_accuracy: 0.8268\n",
            "Epoch 42/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4575 - accuracy: 0.7865 - val_loss: 0.4435 - val_accuracy: 0.8268\n",
            "Epoch 43/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4568 - accuracy: 0.7865 - val_loss: 0.4433 - val_accuracy: 0.8268\n",
            "Epoch 44/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4562 - accuracy: 0.7865 - val_loss: 0.4425 - val_accuracy: 0.8268\n",
            "Epoch 45/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4554 - accuracy: 0.7865 - val_loss: 0.4418 - val_accuracy: 0.8268\n",
            "Epoch 46/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7865 - val_loss: 0.4412 - val_accuracy: 0.8268\n",
            "Epoch 47/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4545 - accuracy: 0.7893 - val_loss: 0.4413 - val_accuracy: 0.8380\n",
            "Epoch 48/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4538 - accuracy: 0.7879 - val_loss: 0.4403 - val_accuracy: 0.8324\n",
            "Epoch 49/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4533 - accuracy: 0.7879 - val_loss: 0.4398 - val_accuracy: 0.8324\n",
            "Epoch 50/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4531 - accuracy: 0.7865 - val_loss: 0.4401 - val_accuracy: 0.8380\n",
            "Epoch 51/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4526 - accuracy: 0.7865 - val_loss: 0.4396 - val_accuracy: 0.8380\n",
            "Epoch 52/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4524 - accuracy: 0.7865 - val_loss: 0.4394 - val_accuracy: 0.8380\n",
            "Epoch 53/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7879 - val_loss: 0.4403 - val_accuracy: 0.8380\n",
            "Epoch 54/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7893 - val_loss: 0.4398 - val_accuracy: 0.8380\n",
            "Epoch 55/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4513 - accuracy: 0.7921 - val_loss: 0.4391 - val_accuracy: 0.8380\n",
            "Epoch 56/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7935 - val_loss: 0.4387 - val_accuracy: 0.8380\n",
            "Epoch 57/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7921 - val_loss: 0.4384 - val_accuracy: 0.8380\n",
            "Epoch 58/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4504 - accuracy: 0.7907 - val_loss: 0.4379 - val_accuracy: 0.8380\n",
            "Epoch 59/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7907 - val_loss: 0.4376 - val_accuracy: 0.8380\n",
            "Epoch 60/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4501 - accuracy: 0.7879 - val_loss: 0.4367 - val_accuracy: 0.8380\n",
            "Epoch 61/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7879 - val_loss: 0.4368 - val_accuracy: 0.8380\n",
            "Epoch 62/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4492 - accuracy: 0.7879 - val_loss: 0.4371 - val_accuracy: 0.8380\n",
            "Epoch 63/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4490 - accuracy: 0.7879 - val_loss: 0.4369 - val_accuracy: 0.8380\n",
            "Epoch 64/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7893 - val_loss: 0.4366 - val_accuracy: 0.8380\n",
            "Epoch 65/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7879 - val_loss: 0.4370 - val_accuracy: 0.8380\n",
            "Epoch 66/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7879 - val_loss: 0.4363 - val_accuracy: 0.8380\n",
            "Epoch 67/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7879 - val_loss: 0.4369 - val_accuracy: 0.8380\n",
            "Epoch 68/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4479 - accuracy: 0.7893 - val_loss: 0.4364 - val_accuracy: 0.8380\n",
            "Epoch 69/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7893 - val_loss: 0.4359 - val_accuracy: 0.8380\n",
            "Epoch 70/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7879 - val_loss: 0.4361 - val_accuracy: 0.8380\n",
            "Epoch 71/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7907 - val_loss: 0.4357 - val_accuracy: 0.8380\n",
            "Epoch 72/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7921 - val_loss: 0.4358 - val_accuracy: 0.8380\n",
            "Epoch 73/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7921 - val_loss: 0.4361 - val_accuracy: 0.8380\n",
            "Epoch 74/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7893 - val_loss: 0.4358 - val_accuracy: 0.8380\n",
            "Epoch 75/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7893 - val_loss: 0.4364 - val_accuracy: 0.8380\n",
            "Epoch 76/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7879 - val_loss: 0.4360 - val_accuracy: 0.8380\n",
            "Epoch 77/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7879 - val_loss: 0.4359 - val_accuracy: 0.8380\n",
            "Epoch 78/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7893 - val_loss: 0.4360 - val_accuracy: 0.8380\n",
            "Epoch 79/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7865 - val_loss: 0.4367 - val_accuracy: 0.8324\n",
            "Epoch 80/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7893 - val_loss: 0.4361 - val_accuracy: 0.8324\n",
            "Epoch 81/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4455 - accuracy: 0.7893 - val_loss: 0.4355 - val_accuracy: 0.8324\n",
            "Epoch 82/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7893 - val_loss: 0.4359 - val_accuracy: 0.8324\n",
            "Epoch 83/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.7907 - val_loss: 0.4360 - val_accuracy: 0.8324\n",
            "Epoch 84/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7865 - val_loss: 0.4343 - val_accuracy: 0.8324\n",
            "Epoch 85/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4450 - accuracy: 0.7893 - val_loss: 0.4355 - val_accuracy: 0.8324\n",
            "Epoch 86/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7879 - val_loss: 0.4352 - val_accuracy: 0.8324\n",
            "Epoch 87/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4442 - accuracy: 0.7879 - val_loss: 0.4353 - val_accuracy: 0.8324\n",
            "Epoch 88/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7893 - val_loss: 0.4344 - val_accuracy: 0.8380\n",
            "Epoch 89/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4442 - accuracy: 0.7879 - val_loss: 0.4334 - val_accuracy: 0.8324\n",
            "Epoch 90/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7879 - val_loss: 0.4334 - val_accuracy: 0.8324\n",
            "Epoch 91/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7879 - val_loss: 0.4335 - val_accuracy: 0.8324\n",
            "Epoch 92/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4436 - accuracy: 0.7949 - val_loss: 0.4329 - val_accuracy: 0.8324\n",
            "Epoch 93/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4435 - accuracy: 0.7963 - val_loss: 0.4325 - val_accuracy: 0.8324\n",
            "Epoch 94/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4434 - accuracy: 0.7921 - val_loss: 0.4323 - val_accuracy: 0.8324\n",
            "Epoch 95/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7935 - val_loss: 0.4346 - val_accuracy: 0.8324\n",
            "Epoch 96/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4433 - accuracy: 0.7921 - val_loss: 0.4349 - val_accuracy: 0.8324\n",
            "Epoch 97/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4431 - accuracy: 0.7949 - val_loss: 0.4336 - val_accuracy: 0.8324\n",
            "Epoch 98/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4429 - accuracy: 0.7865 - val_loss: 0.4326 - val_accuracy: 0.8324\n",
            "Epoch 99/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4426 - accuracy: 0.7879 - val_loss: 0.4324 - val_accuracy: 0.8324\n",
            "Epoch 100/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7907 - val_loss: 0.4326 - val_accuracy: 0.8324\n",
            "Epoch 101/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4427 - accuracy: 0.7865 - val_loss: 0.4331 - val_accuracy: 0.8324\n",
            "Epoch 102/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4424 - accuracy: 0.7893 - val_loss: 0.4327 - val_accuracy: 0.8324\n",
            "Epoch 103/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4424 - accuracy: 0.7893 - val_loss: 0.4324 - val_accuracy: 0.8324\n",
            "Epoch 104/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7879 - val_loss: 0.4322 - val_accuracy: 0.8324\n",
            "Epoch 105/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4419 - accuracy: 0.7893 - val_loss: 0.4320 - val_accuracy: 0.8324\n",
            "Epoch 106/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4419 - accuracy: 0.7907 - val_loss: 0.4318 - val_accuracy: 0.8324\n",
            "Epoch 107/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4418 - accuracy: 0.7893 - val_loss: 0.4317 - val_accuracy: 0.8324\n",
            "Epoch 108/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7907 - val_loss: 0.4313 - val_accuracy: 0.8324\n",
            "Epoch 109/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7907 - val_loss: 0.4316 - val_accuracy: 0.8324\n",
            "Epoch 110/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4414 - accuracy: 0.7893 - val_loss: 0.4311 - val_accuracy: 0.8324\n",
            "Epoch 111/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7893 - val_loss: 0.4322 - val_accuracy: 0.8324\n",
            "Epoch 112/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4411 - accuracy: 0.7907 - val_loss: 0.4316 - val_accuracy: 0.8324\n",
            "Epoch 113/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4413 - accuracy: 0.7879 - val_loss: 0.4311 - val_accuracy: 0.8324\n",
            "Epoch 114/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4409 - accuracy: 0.7893 - val_loss: 0.4310 - val_accuracy: 0.8324\n",
            "Epoch 115/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4409 - accuracy: 0.7879 - val_loss: 0.4308 - val_accuracy: 0.8324\n",
            "Epoch 116/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7851 - val_loss: 0.4302 - val_accuracy: 0.8324\n",
            "Epoch 117/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7907 - val_loss: 0.4311 - val_accuracy: 0.8324\n",
            "Epoch 118/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7893 - val_loss: 0.4314 - val_accuracy: 0.8324\n",
            "Epoch 119/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7893 - val_loss: 0.4316 - val_accuracy: 0.8324\n",
            "Epoch 120/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4404 - accuracy: 0.7907 - val_loss: 0.4321 - val_accuracy: 0.8324\n",
            "Epoch 121/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7893 - val_loss: 0.4307 - val_accuracy: 0.8324\n",
            "Epoch 122/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4400 - accuracy: 0.7907 - val_loss: 0.4306 - val_accuracy: 0.8324\n",
            "Epoch 123/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7893 - val_loss: 0.4297 - val_accuracy: 0.8324\n",
            "Epoch 124/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4396 - accuracy: 0.7907 - val_loss: 0.4293 - val_accuracy: 0.8324\n",
            "Epoch 125/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4395 - accuracy: 0.7879 - val_loss: 0.4292 - val_accuracy: 0.8324\n",
            "Epoch 126/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7907 - val_loss: 0.4289 - val_accuracy: 0.8324\n",
            "Epoch 127/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7921 - val_loss: 0.4287 - val_accuracy: 0.8324\n",
            "Epoch 128/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7907 - val_loss: 0.4287 - val_accuracy: 0.8324\n",
            "Epoch 129/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4383 - accuracy: 0.7935 - val_loss: 0.4290 - val_accuracy: 0.8324\n",
            "Epoch 130/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4382 - accuracy: 0.7921 - val_loss: 0.4280 - val_accuracy: 0.8324\n",
            "Epoch 131/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4380 - accuracy: 0.7921 - val_loss: 0.4292 - val_accuracy: 0.8324\n",
            "Epoch 132/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7935 - val_loss: 0.4288 - val_accuracy: 0.8324\n",
            "Epoch 133/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7907 - val_loss: 0.4281 - val_accuracy: 0.8324\n",
            "Epoch 134/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4373 - accuracy: 0.7935 - val_loss: 0.4276 - val_accuracy: 0.8324\n",
            "Epoch 135/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.7921 - val_loss: 0.4274 - val_accuracy: 0.8324\n",
            "Epoch 136/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4371 - accuracy: 0.7978 - val_loss: 0.4281 - val_accuracy: 0.8268\n",
            "Epoch 137/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4368 - accuracy: 0.7935 - val_loss: 0.4274 - val_accuracy: 0.8268\n",
            "Epoch 138/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4364 - accuracy: 0.7921 - val_loss: 0.4271 - val_accuracy: 0.8268\n",
            "Epoch 139/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7949 - val_loss: 0.4270 - val_accuracy: 0.8268\n",
            "Epoch 140/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7907 - val_loss: 0.4260 - val_accuracy: 0.8324\n",
            "Epoch 141/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4358 - accuracy: 0.7907 - val_loss: 0.4259 - val_accuracy: 0.8324\n",
            "Epoch 142/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7935 - val_loss: 0.4251 - val_accuracy: 0.8268\n",
            "Epoch 143/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4356 - accuracy: 0.7978 - val_loss: 0.4251 - val_accuracy: 0.8268\n",
            "Epoch 144/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7978 - val_loss: 0.4251 - val_accuracy: 0.8268\n",
            "Epoch 145/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7978 - val_loss: 0.4245 - val_accuracy: 0.8268\n",
            "Epoch 146/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4350 - accuracy: 0.7963 - val_loss: 0.4243 - val_accuracy: 0.8324\n",
            "Epoch 147/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7949 - val_loss: 0.4242 - val_accuracy: 0.8268\n",
            "Epoch 148/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4343 - accuracy: 0.7963 - val_loss: 0.4238 - val_accuracy: 0.8268\n",
            "Epoch 149/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7978 - val_loss: 0.4231 - val_accuracy: 0.8268\n",
            "Epoch 150/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4342 - accuracy: 0.7963 - val_loss: 0.4230 - val_accuracy: 0.8268\n",
            "Epoch 151/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4338 - accuracy: 0.7963 - val_loss: 0.4230 - val_accuracy: 0.8268\n",
            "Epoch 152/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7978 - val_loss: 0.4219 - val_accuracy: 0.8268\n",
            "Epoch 153/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4335 - accuracy: 0.7963 - val_loss: 0.4216 - val_accuracy: 0.8268\n",
            "Epoch 154/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7963 - val_loss: 0.4216 - val_accuracy: 0.8268\n",
            "Epoch 155/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7978 - val_loss: 0.4208 - val_accuracy: 0.8268\n",
            "Epoch 156/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4328 - accuracy: 0.7935 - val_loss: 0.4213 - val_accuracy: 0.8268\n",
            "Epoch 157/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7978 - val_loss: 0.4212 - val_accuracy: 0.8268\n",
            "Epoch 158/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4325 - accuracy: 0.7978 - val_loss: 0.4215 - val_accuracy: 0.8268\n",
            "Epoch 159/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7963 - val_loss: 0.4204 - val_accuracy: 0.8268\n",
            "Epoch 160/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4322 - accuracy: 0.7963 - val_loss: 0.4211 - val_accuracy: 0.8324\n",
            "Epoch 161/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7963 - val_loss: 0.4203 - val_accuracy: 0.8268\n",
            "Epoch 162/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4321 - accuracy: 0.7963 - val_loss: 0.4205 - val_accuracy: 0.8324\n",
            "Epoch 163/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7949 - val_loss: 0.4200 - val_accuracy: 0.8324\n",
            "Epoch 164/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7963 - val_loss: 0.4179 - val_accuracy: 0.8324\n",
            "Epoch 165/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7963 - val_loss: 0.4179 - val_accuracy: 0.8324\n",
            "Epoch 166/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7963 - val_loss: 0.4185 - val_accuracy: 0.8324\n",
            "Epoch 167/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7963 - val_loss: 0.4179 - val_accuracy: 0.8324\n",
            "Epoch 168/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4307 - accuracy: 0.7949 - val_loss: 0.4173 - val_accuracy: 0.8324\n",
            "Epoch 169/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7949 - val_loss: 0.4175 - val_accuracy: 0.8324\n",
            "Epoch 170/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4303 - accuracy: 0.7949 - val_loss: 0.4167 - val_accuracy: 0.8324\n",
            "Epoch 171/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7963 - val_loss: 0.4163 - val_accuracy: 0.8324\n",
            "Epoch 172/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7992 - val_loss: 0.4158 - val_accuracy: 0.8324\n",
            "Epoch 173/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7949 - val_loss: 0.4160 - val_accuracy: 0.8324\n",
            "Epoch 174/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7949 - val_loss: 0.4163 - val_accuracy: 0.8324\n",
            "Epoch 175/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4295 - accuracy: 0.7949 - val_loss: 0.4157 - val_accuracy: 0.8324\n",
            "Epoch 176/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7978 - val_loss: 0.4158 - val_accuracy: 0.8324\n",
            "Epoch 177/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4293 - accuracy: 0.7992 - val_loss: 0.4154 - val_accuracy: 0.8324\n",
            "Epoch 178/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4291 - accuracy: 0.8006 - val_loss: 0.4150 - val_accuracy: 0.8324\n",
            "Epoch 179/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7978 - val_loss: 0.4145 - val_accuracy: 0.8324\n",
            "Epoch 180/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7978 - val_loss: 0.4142 - val_accuracy: 0.8324\n",
            "Epoch 181/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4288 - accuracy: 0.7978 - val_loss: 0.4146 - val_accuracy: 0.8324\n",
            "Epoch 182/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.8020 - val_loss: 0.4152 - val_accuracy: 0.8380\n",
            "Epoch 183/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.8006 - val_loss: 0.4127 - val_accuracy: 0.8380\n",
            "Epoch 184/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4285 - accuracy: 0.7949 - val_loss: 0.4120 - val_accuracy: 0.8324\n",
            "Epoch 185/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.7963 - val_loss: 0.4116 - val_accuracy: 0.8324\n",
            "Epoch 186/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.7963 - val_loss: 0.4119 - val_accuracy: 0.8324\n",
            "Epoch 187/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7992 - val_loss: 0.4126 - val_accuracy: 0.8380\n",
            "Epoch 188/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.8006 - val_loss: 0.4121 - val_accuracy: 0.8324\n",
            "Epoch 189/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.8006 - val_loss: 0.4121 - val_accuracy: 0.8324\n",
            "Epoch 190/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7992 - val_loss: 0.4127 - val_accuracy: 0.8380\n",
            "Epoch 191/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.7992 - val_loss: 0.4103 - val_accuracy: 0.8436\n",
            "Epoch 192/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.8006 - val_loss: 0.4102 - val_accuracy: 0.8436\n",
            "Epoch 193/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.7978 - val_loss: 0.4112 - val_accuracy: 0.8436\n",
            "Epoch 194/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7992 - val_loss: 0.4121 - val_accuracy: 0.8380\n",
            "Epoch 195/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.8006 - val_loss: 0.4122 - val_accuracy: 0.8380\n",
            "Epoch 196/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.8006 - val_loss: 0.4116 - val_accuracy: 0.8380\n",
            "Epoch 197/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.8034 - val_loss: 0.4116 - val_accuracy: 0.8380\n",
            "Epoch 198/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.8020 - val_loss: 0.4116 - val_accuracy: 0.8380\n",
            "Epoch 199/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8034 - val_loss: 0.4114 - val_accuracy: 0.8380\n",
            "Epoch 200/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4269 - accuracy: 0.8034 - val_loss: 0.4115 - val_accuracy: 0.8436\n",
            "Epoch 201/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8034 - val_loss: 0.4111 - val_accuracy: 0.8436\n",
            "Epoch 202/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4268 - accuracy: 0.8006 - val_loss: 0.4108 - val_accuracy: 0.8436\n",
            "Epoch 203/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4268 - accuracy: 0.8006 - val_loss: 0.4110 - val_accuracy: 0.8436\n",
            "Epoch 204/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8020 - val_loss: 0.4105 - val_accuracy: 0.8436\n",
            "Epoch 205/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4265 - accuracy: 0.8034 - val_loss: 0.4105 - val_accuracy: 0.8436\n",
            "Epoch 206/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4265 - accuracy: 0.8020 - val_loss: 0.4099 - val_accuracy: 0.8436\n",
            "Epoch 207/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.8006 - val_loss: 0.4098 - val_accuracy: 0.8436\n",
            "Epoch 208/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8034 - val_loss: 0.4099 - val_accuracy: 0.8436\n",
            "Epoch 209/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4263 - accuracy: 0.8020 - val_loss: 0.4108 - val_accuracy: 0.8436\n",
            "Epoch 210/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.8034 - val_loss: 0.4102 - val_accuracy: 0.8436\n",
            "Epoch 211/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8020 - val_loss: 0.4104 - val_accuracy: 0.8436\n",
            "Epoch 212/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8020 - val_loss: 0.4113 - val_accuracy: 0.8436\n",
            "Epoch 213/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8034 - val_loss: 0.4112 - val_accuracy: 0.8436\n",
            "Epoch 214/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.8034 - val_loss: 0.4114 - val_accuracy: 0.8436\n",
            "Epoch 215/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8034 - val_loss: 0.4100 - val_accuracy: 0.8436\n",
            "Epoch 216/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4258 - accuracy: 0.8034 - val_loss: 0.4103 - val_accuracy: 0.8436\n",
            "Epoch 217/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.8048 - val_loss: 0.4110 - val_accuracy: 0.8436\n",
            "Epoch 218/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4259 - accuracy: 0.8034 - val_loss: 0.4111 - val_accuracy: 0.8436\n",
            "Epoch 219/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4255 - accuracy: 0.8062 - val_loss: 0.4105 - val_accuracy: 0.8436\n",
            "Epoch 220/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.8062 - val_loss: 0.4107 - val_accuracy: 0.8436\n",
            "Epoch 221/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4255 - accuracy: 0.8062 - val_loss: 0.4114 - val_accuracy: 0.8436\n",
            "Epoch 222/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4255 - accuracy: 0.8048 - val_loss: 0.4106 - val_accuracy: 0.8436\n",
            "Epoch 223/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.8062 - val_loss: 0.4099 - val_accuracy: 0.8436\n",
            "Epoch 224/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4253 - accuracy: 0.8090 - val_loss: 0.4110 - val_accuracy: 0.8436\n",
            "Epoch 225/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4251 - accuracy: 0.8090 - val_loss: 0.4102 - val_accuracy: 0.8436\n",
            "Epoch 226/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.8090 - val_loss: 0.4101 - val_accuracy: 0.8436\n",
            "Epoch 227/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.8090 - val_loss: 0.4109 - val_accuracy: 0.8436\n",
            "Epoch 228/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4250 - accuracy: 0.8090 - val_loss: 0.4117 - val_accuracy: 0.8436\n",
            "Epoch 229/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.8104 - val_loss: 0.4110 - val_accuracy: 0.8436\n",
            "Epoch 230/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.8090 - val_loss: 0.4124 - val_accuracy: 0.8380\n",
            "Epoch 231/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4253 - accuracy: 0.8090 - val_loss: 0.4121 - val_accuracy: 0.8436\n",
            "Epoch 232/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4248 - accuracy: 0.8104 - val_loss: 0.4112 - val_accuracy: 0.8436\n",
            "Epoch 233/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4246 - accuracy: 0.8104 - val_loss: 0.4115 - val_accuracy: 0.8436\n",
            "Epoch 234/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4248 - accuracy: 0.8104 - val_loss: 0.4113 - val_accuracy: 0.8436\n",
            "Epoch 235/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.8090 - val_loss: 0.4109 - val_accuracy: 0.8436\n",
            "Epoch 236/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4247 - accuracy: 0.8104 - val_loss: 0.4117 - val_accuracy: 0.8436\n",
            "Epoch 237/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8104 - val_loss: 0.4107 - val_accuracy: 0.8436\n",
            "Epoch 238/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4244 - accuracy: 0.8104 - val_loss: 0.4109 - val_accuracy: 0.8436\n",
            "Epoch 239/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8104 - val_loss: 0.4107 - val_accuracy: 0.8436\n",
            "Epoch 240/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4245 - accuracy: 0.8118 - val_loss: 0.4116 - val_accuracy: 0.8436\n",
            "Epoch 241/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8090 - val_loss: 0.4109 - val_accuracy: 0.8436\n",
            "Epoch 242/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4244 - accuracy: 0.8090 - val_loss: 0.4090 - val_accuracy: 0.8436\n",
            "Epoch 243/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4242 - accuracy: 0.8104 - val_loss: 0.4100 - val_accuracy: 0.8436\n",
            "Epoch 244/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8090 - val_loss: 0.4092 - val_accuracy: 0.8436\n",
            "Epoch 245/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4241 - accuracy: 0.8146 - val_loss: 0.4105 - val_accuracy: 0.8436\n",
            "Epoch 246/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8118 - val_loss: 0.4112 - val_accuracy: 0.8436\n",
            "Epoch 247/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.8118 - val_loss: 0.4114 - val_accuracy: 0.8436\n",
            "Epoch 248/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4237 - accuracy: 0.8104 - val_loss: 0.4117 - val_accuracy: 0.8436\n",
            "Epoch 249/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4239 - accuracy: 0.8118 - val_loss: 0.4107 - val_accuracy: 0.8436\n",
            "Epoch 250/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.8118 - val_loss: 0.4112 - val_accuracy: 0.8436\n",
            "Epoch 251/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4237 - accuracy: 0.8118 - val_loss: 0.4111 - val_accuracy: 0.8436\n",
            "Epoch 252/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.8118 - val_loss: 0.4114 - val_accuracy: 0.8436\n",
            "Epoch 253/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4237 - accuracy: 0.8118 - val_loss: 0.4109 - val_accuracy: 0.8436\n",
            "Epoch 254/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.8118 - val_loss: 0.4107 - val_accuracy: 0.8436\n",
            "Epoch 255/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4234 - accuracy: 0.8118 - val_loss: 0.4110 - val_accuracy: 0.8436\n",
            "Epoch 256/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.8118 - val_loss: 0.4105 - val_accuracy: 0.8436\n",
            "Epoch 257/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4231 - accuracy: 0.8118 - val_loss: 0.4107 - val_accuracy: 0.8436\n",
            "Epoch 258/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.8132 - val_loss: 0.4110 - val_accuracy: 0.8436\n",
            "Epoch 259/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.8132 - val_loss: 0.4117 - val_accuracy: 0.8436\n",
            "Epoch 260/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.8118 - val_loss: 0.4129 - val_accuracy: 0.8436\n",
            "Epoch 261/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.8132 - val_loss: 0.4117 - val_accuracy: 0.8436\n",
            "Epoch 262/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.8118 - val_loss: 0.4116 - val_accuracy: 0.8436\n",
            "Epoch 263/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.8132 - val_loss: 0.4118 - val_accuracy: 0.8436\n",
            "Epoch 264/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4227 - accuracy: 0.8160 - val_loss: 0.4130 - val_accuracy: 0.8436\n",
            "Epoch 265/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4227 - accuracy: 0.8146 - val_loss: 0.4140 - val_accuracy: 0.8380\n",
            "Epoch 266/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.8146 - val_loss: 0.4130 - val_accuracy: 0.8436\n",
            "Epoch 267/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8160 - val_loss: 0.4138 - val_accuracy: 0.8436\n",
            "Epoch 268/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8160 - val_loss: 0.4133 - val_accuracy: 0.8436\n",
            "Epoch 269/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4227 - accuracy: 0.8160 - val_loss: 0.4140 - val_accuracy: 0.8436\n",
            "Epoch 270/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.8160 - val_loss: 0.4132 - val_accuracy: 0.8436\n",
            "Epoch 271/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4228 - accuracy: 0.8146 - val_loss: 0.4132 - val_accuracy: 0.8436\n",
            "Epoch 272/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.8174 - val_loss: 0.4127 - val_accuracy: 0.8436\n",
            "Epoch 273/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4223 - accuracy: 0.8174 - val_loss: 0.4132 - val_accuracy: 0.8436\n",
            "Epoch 274/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4223 - accuracy: 0.8160 - val_loss: 0.4146 - val_accuracy: 0.8380\n",
            "Epoch 275/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.8174 - val_loss: 0.4140 - val_accuracy: 0.8436\n",
            "Epoch 276/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.8174 - val_loss: 0.4134 - val_accuracy: 0.8436\n",
            "Epoch 277/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8146 - val_loss: 0.4146 - val_accuracy: 0.8380\n",
            "Epoch 278/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8132 - val_loss: 0.4123 - val_accuracy: 0.8436\n",
            "Epoch 279/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.8174 - val_loss: 0.4135 - val_accuracy: 0.8436\n",
            "Epoch 280/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.8146 - val_loss: 0.4128 - val_accuracy: 0.8436\n",
            "Epoch 281/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.8160 - val_loss: 0.4127 - val_accuracy: 0.8436\n",
            "Epoch 282/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.8188 - val_loss: 0.4135 - val_accuracy: 0.8436\n",
            "Epoch 283/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.8160 - val_loss: 0.4123 - val_accuracy: 0.8436\n",
            "Epoch 284/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.8160 - val_loss: 0.4127 - val_accuracy: 0.8436\n",
            "Epoch 285/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.8174 - val_loss: 0.4133 - val_accuracy: 0.8436\n",
            "Epoch 286/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.8174 - val_loss: 0.4120 - val_accuracy: 0.8436\n",
            "Epoch 287/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.8160 - val_loss: 0.4122 - val_accuracy: 0.8436\n",
            "Epoch 288/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.8174 - val_loss: 0.4127 - val_accuracy: 0.8436\n",
            "Epoch 289/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.8188 - val_loss: 0.4127 - val_accuracy: 0.8436\n",
            "Epoch 290/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.8174 - val_loss: 0.4118 - val_accuracy: 0.8436\n",
            "Epoch 291/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.8160 - val_loss: 0.4119 - val_accuracy: 0.8436\n",
            "Epoch 292/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.8160 - val_loss: 0.4126 - val_accuracy: 0.8436\n",
            "Epoch 293/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.8146 - val_loss: 0.4118 - val_accuracy: 0.8436\n",
            "Epoch 294/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.8160 - val_loss: 0.4119 - val_accuracy: 0.8436\n",
            "Epoch 295/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4213 - accuracy: 0.8188 - val_loss: 0.4124 - val_accuracy: 0.8436\n",
            "Epoch 296/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.8188 - val_loss: 0.4132 - val_accuracy: 0.8436\n",
            "Epoch 297/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4215 - accuracy: 0.8188 - val_loss: 0.4124 - val_accuracy: 0.8436\n",
            "Epoch 298/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.8202 - val_loss: 0.4124 - val_accuracy: 0.8436\n",
            "Epoch 299/300\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4212 - accuracy: 0.8174 - val_loss: 0.4117 - val_accuracy: 0.8436\n",
            "Epoch 300/300\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.8160 - val_loss: 0.4117 - val_accuracy: 0.8436\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# fungsi API\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "# fungsi layer\n",
        "data_in = Input(shape=(7,))\n",
        "hidden_1 = Dense(4, activation='relu')(data_in)\n",
        "out = Dense(1, activation='sigmoid')(hidden_1)\n",
        "\n",
        "# combine\n",
        "model = Model(inputs=data_in, outputs=out)\n",
        "\n",
        "# compile\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# train\n",
        "history = model.fit(X_train_final, y_train, epochs=300, validation_data=(X_test_final, y_test))\n",
        "\n",
        "metrics = pd.DataFrame(history.history)\n",
        "metrics.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RN_z-0sj4b_",
        "outputId": "0783bf66-2302-4310-ea35-5ae2ad0bb28b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.93      0.87       104\n",
            "           1       0.89      0.72      0.79        75\n",
            "\n",
            "    accuracy                           0.84       179\n",
            "   macro avg       0.85      0.83      0.83       179\n",
            "weighted avg       0.85      0.84      0.84       179\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#inference\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = model.predict(X_test_final)\n",
        "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp3sBt4WmtSO"
      },
      "source": [
        "## MNIST Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pRRYHE7mvRJ",
        "outputId": "fdedf7a1-67b2-43e0-9ffd-21ec9f973b62"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train/255.0\n",
        "X_test = X_test/255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "6dMzW5FInmfn"
      },
      "outputs": [],
      "source": [
        "def show_image(image):\n",
        "  plt.imshow(image, cmap='binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "zwRl3LPRnyak",
        "outputId": "53d08036-8708-4117-eb3b-d814d10977a6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "show_image(X_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgdJ_Xd8n1Wr",
        "outputId": "b1a317d9-4ed4-47a6-e3b5-9f17e4e42724"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EymeC2k0n3vr",
        "outputId": "f85827ad-eb63-424e-846b-1ed397e099af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "hriz61-oom-I"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=46, test_size=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Bq-6RZDQpEHJ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_ohe = to_categorical(y_train)\n",
        "y_test_ohe = to_categorical(y_test)\n",
        "y_val_ohe = to_categorical(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJGdY7ghpbw3",
        "outputId": "072269da-4970-4e30-887b-0ce140f0274e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0, array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32))"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train[0],y_train_ohe[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JpRRkz4q1bf",
        "outputId": "0320c78f-72a7-4141-c104-633463a66fe2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 256)               200960    \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 32)                8224      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 209,514\n",
            "Trainable params: 209,514\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.3351 - accuracy: 0.9068 - val_loss: 0.1369 - val_accuracy: 0.9600\n",
            "Epoch 2/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.1298 - accuracy: 0.9624 - val_loss: 0.1114 - val_accuracy: 0.9663\n",
            "Epoch 3/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0885 - accuracy: 0.9735 - val_loss: 0.0758 - val_accuracy: 0.9773\n",
            "Epoch 4/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0640 - accuracy: 0.9808 - val_loss: 0.0824 - val_accuracy: 0.9775\n",
            "Epoch 5/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0480 - accuracy: 0.9849 - val_loss: 0.0659 - val_accuracy: 0.9812\n",
            "Epoch 6/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0374 - accuracy: 0.9885 - val_loss: 0.0665 - val_accuracy: 0.9785\n",
            "Epoch 7/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0295 - accuracy: 0.9914 - val_loss: 0.0618 - val_accuracy: 0.9817\n",
            "Epoch 8/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0229 - accuracy: 0.9934 - val_loss: 0.0709 - val_accuracy: 0.9812\n",
            "Epoch 9/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0184 - accuracy: 0.9947 - val_loss: 0.0654 - val_accuracy: 0.9818\n",
            "Epoch 10/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0158 - accuracy: 0.9954 - val_loss: 0.0578 - val_accuracy: 0.9845\n",
            "Epoch 11/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0134 - accuracy: 0.9961 - val_loss: 0.0718 - val_accuracy: 0.9813\n",
            "Epoch 12/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.0731 - val_accuracy: 0.9830\n",
            "Epoch 13/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.0795 - val_accuracy: 0.9793\n",
            "Epoch 14/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 0.1046 - val_accuracy: 0.9762\n",
            "Epoch 15/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0112 - accuracy: 0.9965 - val_loss: 0.0767 - val_accuracy: 0.9810\n",
            "Epoch 16/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.0698 - val_accuracy: 0.9847\n",
            "Epoch 17/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.0852 - val_accuracy: 0.9805\n",
            "Epoch 18/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.0904 - val_accuracy: 0.9803\n",
            "Epoch 19/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.0702 - val_accuracy: 0.9840\n",
            "Epoch 20/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0849 - val_accuracy: 0.9800\n",
            "Epoch 21/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 0.0818 - val_accuracy: 0.9825\n",
            "Epoch 22/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0077 - accuracy: 0.9972 - val_loss: 0.0802 - val_accuracy: 0.9837\n",
            "Epoch 23/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0801 - val_accuracy: 0.9828\n",
            "Epoch 24/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0735 - val_accuracy: 0.9868\n",
            "Epoch 25/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0913 - val_accuracy: 0.9820\n",
            "Epoch 26/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0127 - accuracy: 0.9959 - val_loss: 0.1019 - val_accuracy: 0.9825\n",
            "Epoch 27/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.0903 - val_accuracy: 0.9837\n",
            "Epoch 28/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0841 - val_accuracy: 0.9827\n",
            "Epoch 29/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0794 - val_accuracy: 0.9848\n",
            "Epoch 30/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 5.1335e-04 - accuracy: 0.9999 - val_loss: 0.0742 - val_accuracy: 0.9862\n",
            "Epoch 31/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 1.2844e-04 - accuracy: 1.0000 - val_loss: 0.0755 - val_accuracy: 0.9857\n",
            "Epoch 32/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 7.6271e-05 - accuracy: 1.0000 - val_loss: 0.0766 - val_accuracy: 0.9863\n",
            "Epoch 33/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 5.8254e-05 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 0.9863\n",
            "Epoch 34/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 4.8078e-05 - accuracy: 1.0000 - val_loss: 0.0775 - val_accuracy: 0.9865\n",
            "Epoch 35/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 4.1732e-05 - accuracy: 1.0000 - val_loss: 0.0780 - val_accuracy: 0.9868\n",
            "Epoch 36/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 3.5583e-05 - accuracy: 1.0000 - val_loss: 0.0785 - val_accuracy: 0.9865\n",
            "Epoch 37/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 3.0813e-05 - accuracy: 1.0000 - val_loss: 0.0786 - val_accuracy: 0.9862\n",
            "Epoch 38/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 2.6535e-05 - accuracy: 1.0000 - val_loss: 0.0795 - val_accuracy: 0.9863\n",
            "Epoch 39/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 2.2737e-05 - accuracy: 1.0000 - val_loss: 0.0793 - val_accuracy: 0.9868\n",
            "Epoch 40/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 2.3077e-05 - accuracy: 1.0000 - val_loss: 0.0834 - val_accuracy: 0.9860\n",
            "Epoch 41/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0269 - accuracy: 0.9923 - val_loss: 0.1059 - val_accuracy: 0.9812\n",
            "Epoch 42/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.0997 - val_accuracy: 0.9825\n",
            "Epoch 43/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0903 - val_accuracy: 0.9833\n",
            "Epoch 44/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 3.1518e-04 - accuracy: 1.0000 - val_loss: 0.0879 - val_accuracy: 0.9842\n",
            "Epoch 45/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 1.1422e-04 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 0.9837\n",
            "Epoch 46/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 7.6707e-05 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 0.9842\n",
            "Epoch 47/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 6.1663e-05 - accuracy: 1.0000 - val_loss: 0.0891 - val_accuracy: 0.9840\n",
            "Epoch 48/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 5.0968e-05 - accuracy: 1.0000 - val_loss: 0.0889 - val_accuracy: 0.9845\n",
            "Epoch 49/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 4.2754e-05 - accuracy: 1.0000 - val_loss: 0.0892 - val_accuracy: 0.9850\n",
            "Epoch 50/50\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 3.6193e-05 - accuracy: 1.0000 - val_loss: 0.0888 - val_accuracy: 0.9847\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28,28)))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# compile\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# train\n",
        "history = model.fit(X_train, y_train_ohe, epochs=50, batch_size=128, validation_data=(X_val, y_val_ohe))\n",
        "\n",
        "metrics = pd.DataFrame(history.history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "aFB4UkdnuhcN",
        "outputId": "b04e479f-9389-41bc-f6ab-aadd44ef24bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "metrics[['accuracy','val_accuracy']].plot()\n",
        "metrics[['loss','val_loss']].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "GHF23ofMyUfQ",
        "outputId": "17d2bdf7-79c3-4c46-ab0a-90fa54781ce0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "new_data = X_test[100]\n",
        "show_image(new_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WL2zhW1hyaou",
        "outputId": "2382c3f6-285e-4c87-d3aa-47b385bbc799"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred = model.predict(new_data.reshape((-1,28,28)))\n",
        "pred.argmax()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTDGPfx6zUpQ",
        "outputId": "fb7e6678-e23d-4d68-da16-f54ae5f7af7c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test[100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "sDclyTs2zmkr"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred = y_pred.argmax(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cSO3HTGz1BJ",
        "outputId": "17849db1-9136-43d4-eb89-1e8d71582ac1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       980\n",
            "           1       0.99      0.99      0.99      1135\n",
            "           2       0.98      0.99      0.98      1032\n",
            "           3       0.98      0.98      0.98      1010\n",
            "           4       0.99      0.98      0.98       982\n",
            "           5       0.99      0.98      0.98       892\n",
            "           6       0.99      0.99      0.99       958\n",
            "           7       0.99      0.98      0.98      1028\n",
            "           8       0.98      0.98      0.98       974\n",
            "           9       0.97      0.98      0.98      1009\n",
            "\n",
            "    accuracy                           0.98     10000\n",
            "   macro avg       0.98      0.98      0.98     10000\n",
            "weighted avg       0.98      0.98      0.98     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test,y_pred))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of nn_lecture.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
