{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base: \tindonesia is the world's largest island country. and the 14th largest country by land area, at 1,904,569 square kilometers\n",
      " (735,358 square miles). \t \n",
      "\n",
      "Regex: \tindonesia is the world's largest island country. and the th largest country by land area, at ,, square kilometers (, square miles). \t \n",
      "\n",
      "Punctuation: \tindonesia is the worlds largest island country and the th largest country by land area at  square kilometers  square miles \t \n",
      "\n",
      "Whitespace: indonesia is the worlds largest island country and the th largest country by land area at  square kilometers  square miles \n",
      "\n",
      "Word token: ['indonesia', 'is', 'the', 'worlds', 'largest', 'island', 'country', 'and', 'the', 'th', 'largest', 'country', 'by', 'land', 'area', 'at', 'square', 'kilometers', 'square', 'miles']\n",
      "Sentence token: ['indonesia is the worlds largest island country and the th largest country by land area at  square kilometers  square miles'] \n",
      "\n",
      "Stopword: ['indonesia', 'worlds', 'largest', 'island', 'country', 'th', 'largest', 'country', 'land', 'area', 'square', 'kilometers', 'square', 'miles'] \n",
      "\n",
      "Stemming: ['indonesia', 'world', 'largest', 'island', 'countri', 'th', 'largest', 'countri', 'land', 'area', 'squar', 'kilomet', 'squar', 'mile'] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Judan Syamsul\n",
      "[nltk_data]     Hadad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "sentence = \"\\tIndonesia is the world's largest island country. And the 14th largest country by land area, at 1,904,569 square kilometers\\n (735,358 square miles). \\t\"\n",
    "sentence = sentence.lower()\n",
    "print('Base:',sentence,'\\n')\n",
    "\n",
    "import re\n",
    "sentence = re.sub(r'\\d', '', sentence)\n",
    "sentence = re.sub(r'\\n', '', sentence)\n",
    "print('Regex:',sentence,'\\n')\n",
    "\n",
    "import string\n",
    "sentence = sentence.translate(str.maketrans('','', string.punctuation))\n",
    "print('Punctuation:',sentence,'\\n')\n",
    "\n",
    "sentence = sentence.strip()\n",
    "print('Whitespace:',sentence,'\\n')\n",
    "\n",
    "import nltk\n",
    "words_token = nltk.word_tokenize(sentence)\n",
    "sentence_token = nltk.sent_tokenize(sentence)\n",
    "print('Word token:',words_token)\n",
    "print('Sentence token:',sentence_token,'\\n')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [x for x in words_token if x not in stop_words]\n",
    "print('Stopword:',words,'\\n')\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('punkt') #atau nltk.download('popular') \n",
    "ps = PorterStemmer()\n",
    "word_stem = [ps.stem(x) for x in words]\n",
    "print('Stemming:',word_stem,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS: (S\n",
      "  (NP indonesia/NN)\n",
      "  worlds/NNS\n",
      "  largest/JJS\n",
      "  (NP island/NN)\n",
      "  (NP country/NN)\n",
      "  th/RB\n",
      "  largest/JJS\n",
      "  (NP country/NN)\n",
      "  (NP land/NN)\n",
      "  (NP area/NN)\n",
      "  (NP square/NN)\n",
      "  kilometers/NNS\n",
      "  square/VBP\n",
      "  miles/NNS) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "pos_tag = nltk.pos_tag(words)\n",
    "\n",
    "reg_exp  = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "rp = nltk.RegexpParser(reg_exp)\n",
    "result = rp.parse(pos_tag)\n",
    "\n",
    "print('POS:',result,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (GPE Indonesia/NNP)\n",
      "  is/VBZ\n",
      "  the/DT\n",
      "  worlds/NNS\n",
      "  largest/JJS\n",
      "  island/NN\n",
      "  country/NN\n",
      "  and/CC\n",
      "  the/DT\n",
      "  14th/CD\n",
      "  largest/JJS\n",
      "  country/NN\n",
      "  by/IN\n",
      "  land/NN\n",
      "  area/NN\n",
      "  according/VBG\n",
      "  to/TO\n",
      "  (GPE Google/NNP))\n"
     ]
    }
   ],
   "source": [
    "from nltk import ne_chunk, word_tokenize, pos_tag\n",
    "\n",
    "sen = \"Indonesia is the worlds largest island country and the 14th largest country by land area according to Google\"\n",
    "\n",
    "ne_tree = ne_chunk(pos_tag(word_tokenize(sen)))\n",
    "print(ne_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'Saya sedang belajar data science',\n",
    "    'Data science adalah disiplin ilmu yang baru',\n",
    "    'Saya menggunakan Python untuk melakukan pemrosesan data'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'saya': 10,\n",
       " 'sedang': 12,\n",
       " 'belajar': 2,\n",
       " 'data': 3,\n",
       " 'science': 11,\n",
       " 'adalah': 0,\n",
       " 'disiplin': 4,\n",
       " 'ilmu': 5,\n",
       " 'yang': 14,\n",
       " 'baru': 1,\n",
       " 'menggunakan': 7,\n",
       " 'python': 9,\n",
       " 'untuk': 13,\n",
       " 'melakukan': 6,\n",
       " 'pemrosesan': 8}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(corpus)\n",
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['adalah', 'baru', 'belajar', 'data', 'disiplin', 'ilmu',\n",
       "       'melakukan', 'menggunakan', 'pemrosesan', 'python', 'saya',\n",
       "       'science', 'sedang', 'untuk', 'yang'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_mat = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0],\n",
       "       [1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_mat.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adalah</th>\n",
       "      <th>baru</th>\n",
       "      <th>belajar</th>\n",
       "      <th>data</th>\n",
       "      <th>disiplin</th>\n",
       "      <th>ilmu</th>\n",
       "      <th>melakukan</th>\n",
       "      <th>menggunakan</th>\n",
       "      <th>pemrosesan</th>\n",
       "      <th>python</th>\n",
       "      <th>saya</th>\n",
       "      <th>science</th>\n",
       "      <th>sedang</th>\n",
       "      <th>untuk</th>\n",
       "      <th>yang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   adalah  baru  belajar  data  disiplin  ilmu  melakukan  menggunakan  \\\n",
       "0       0     0        1     1         0     0          0            0   \n",
       "1       1     1        0     1         1     1          0            0   \n",
       "2       0     0        0     1         0     0          1            1   \n",
       "\n",
       "   pemrosesan  python  saya  science  sedang  untuk  yang  \n",
       "0           0       0     1        1       1      0     0  \n",
       "1           0       0     0        1       0      0     1  \n",
       "2           1       1     1        0       0      1     0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df = pd.DataFrame(corpus_mat.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "corpus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adalah</th>\n",
       "      <th>baru</th>\n",
       "      <th>belajar</th>\n",
       "      <th>data</th>\n",
       "      <th>disiplin</th>\n",
       "      <th>ilmu</th>\n",
       "      <th>melakukan</th>\n",
       "      <th>menggunakan</th>\n",
       "      <th>pemrosesan</th>\n",
       "      <th>python</th>\n",
       "      <th>saya</th>\n",
       "      <th>science</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   adalah  baru  belajar  data  disiplin  ilmu  melakukan  menggunakan  \\\n",
       "0       0     0        1     1         0     0          0            0   \n",
       "1       1     1        0     1         1     1          0            0   \n",
       "2       0     0        0     1         0     0          1            1   \n",
       "\n",
       "   pemrosesan  python  saya  science  \n",
       "0           0       0     1        1  \n",
       "1           0       0     0        1  \n",
       "2           1       1     1        0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = ['sedang', 'untuk', 'yang']\n",
    "vecstop = CountVectorizer(stop_words=stopwords)\n",
    "corpstop_mat = vecstop.fit_transform(corpus)\n",
    "corpstop_df = pd.DataFrame(corpstop_mat.toarray(), columns=vecstop.get_feature_names_out())\n",
    "corpstop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adalah</th>\n",
       "      <th>baru</th>\n",
       "      <th>belajar</th>\n",
       "      <th>data</th>\n",
       "      <th>disiplin</th>\n",
       "      <th>ilmu</th>\n",
       "      <th>melakukan</th>\n",
       "      <th>menggunakan</th>\n",
       "      <th>pemrosesan</th>\n",
       "      <th>python</th>\n",
       "      <th>saya</th>\n",
       "      <th>science</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   adalah  baru  belajar  data  disiplin  ilmu  melakukan  menggunakan  \\\n",
       "0       0     0        1     0         0     0          0            0   \n",
       "\n",
       "   pemrosesan  python  saya  science  \n",
       "0           0       0     1        0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sent = ['saya belajar NLP']\n",
    "new_sent_mat = vecstop.transform(new_sent)\n",
    "new_sent_df = pd.DataFrame(new_sent_mat.toarray(), columns=vecstop.get_feature_names_out())\n",
    "new_sent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adalah</th>\n",
       "      <th>baru</th>\n",
       "      <th>belajar</th>\n",
       "      <th>data</th>\n",
       "      <th>disiplin</th>\n",
       "      <th>ilmu</th>\n",
       "      <th>melakukan</th>\n",
       "      <th>menggunakan</th>\n",
       "      <th>pemrosesan</th>\n",
       "      <th>python</th>\n",
       "      <th>saya</th>\n",
       "      <th>science</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.631745</td>\n",
       "      <td>0.373119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480458</td>\n",
       "      <td>0.480458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.450504</td>\n",
       "      <td>0.450504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266075</td>\n",
       "      <td>0.450504</td>\n",
       "      <td>0.450504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.342620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.450504</td>\n",
       "      <td>0.450504</td>\n",
       "      <td>0.450504</td>\n",
       "      <td>0.450504</td>\n",
       "      <td>0.342620</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     adalah      baru   belajar      data  disiplin      ilmu  melakukan  \\\n",
       "0  0.000000  0.000000  0.631745  0.373119  0.000000  0.000000   0.000000   \n",
       "1  0.450504  0.450504  0.000000  0.266075  0.450504  0.450504   0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.266075  0.000000  0.000000   0.450504   \n",
       "\n",
       "   menggunakan  pemrosesan    python      saya   science  \n",
       "0     0.000000    0.000000  0.000000  0.480458  0.480458  \n",
       "1     0.000000    0.000000  0.000000  0.000000  0.342620  \n",
       "2     0.450504    0.450504  0.450504  0.342620  0.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(stop_words=stopwords)\n",
    "tfidf.fit(corpus)\n",
    "corp_tfidf_mat = tfidf.transform(corpus)\n",
    "corp_tfidf_df = pd.DataFrame(corp_tfidf_mat.toarray(), columns=tfidf.get_feature_names_out())\n",
    "corp_tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMS Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teks</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[PROMO] Beli paket Flash mulai 1GB di MY TELKO...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.5 GB/30 hari hanya Rp 35 Ribu Spesial buat A...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-07-08 11:47:11.Plg Yth, sisa kuota Flash ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-08-07 11:29:47.Plg Yth, sisa kuota Flash ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.5GB/30 hari hanya Rp 55 Ribu Spesial buat an...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Teks  label\n",
       "0  [PROMO] Beli paket Flash mulai 1GB di MY TELKO...      2\n",
       "1  2.5 GB/30 hari hanya Rp 35 Ribu Spesial buat A...      2\n",
       "2  2016-07-08 11:47:11.Plg Yth, sisa kuota Flash ...      2\n",
       "3  2016-08-07 11:29:47.Plg Yth, sisa kuota Flash ...      2\n",
       "4  4.5GB/30 hari hanya Rp 55 Ribu Spesial buat an...      2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/afifai/hacktiv8-trial-class-spamdetector/main/data/dataset_sms_spam%20_v1.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.label = df.label.map({0: 'SMS Biasa',\n",
    "                         1: 'SMS Spam',\n",
    "                         2: 'SMS Operator'})\n",
    "df.label.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.Teks, df.label, random_state=46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "357    Maafâ€Ÿ Cuma ingatkan soal kontrakan kalau mau d...\n",
       "463    PT.TRI No.V11-3/16 Slamat No.SimCARD Anda mrai...\n",
       "89     HOT PROMO: Internetan kuota 1,2GB/30hr HANYA R...\n",
       "31     Beli 2 Gratis 1 atau beli 1 Diskon 25% tiket K...\n",
       "210    Spesial untuk Anda! Paket Internet Hemat Kuota...\n",
       "                             ...                        \n",
       "411    Pesan resmi dari 3care Bahwa saya mendapatkan ...\n",
       "658    bebas nama1, terus nanti kalau ada tgl libur, ...\n",
       "403    Pelanggan Yth. TRI CARE No.XV/2015 PIN_PEMENAN...\n",
       "442    Plg Yth: Simcard anda mendptkan bonus poin plu...\n",
       "837           Jauh amat jemput di poskamling cilimus dee\n",
       "Name: Teks, Length: 857, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = StopWordRemoverFactory()\n",
    "stopwords = factory.get_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<857x4098 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 14259 stored elements in Compressed Sparse Row format>,\n",
       " <286x4098 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 4025 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = TfidfVectorizer()\n",
    "vect.fit(X_train)\n",
    "X_train_vect = vect.transform(X_train)\n",
    "X_test_vect = vect.transform(X_test)\n",
    "\n",
    "X_train_vect, X_test_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_vect,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   SMS Biasa       0.95      0.95      0.95       138\n",
      "SMS Operator       0.87      0.86      0.87        64\n",
      "    SMS Spam       0.86      0.87      0.86        84\n",
      "\n",
      "    accuracy                           0.91       286\n",
      "   macro avg       0.89      0.89      0.89       286\n",
      "weighted avg       0.91      0.91      0.91       286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = mnb.predict(X_test_vect)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<857x4010 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 12378 stored elements in Compressed Sparse Row format>,\n",
       " <286x4010 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 3397 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = TfidfVectorizer(stop_words=stopwords)\n",
    "vect.fit(X_train)\n",
    "X_train_vect = vect.transform(X_train)\n",
    "X_test_vect = vect.transform(X_test)\n",
    "\n",
    "X_train_vect, X_test_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   SMS Biasa       0.97      0.96      0.97       138\n",
      "SMS Operator       0.89      0.86      0.87        64\n",
      "    SMS Spam       0.89      0.92      0.90        84\n",
      "\n",
      "    accuracy                           0.93       286\n",
      "   macro avg       0.91      0.91      0.91       286\n",
      "weighted avg       0.93      0.93      0.93       286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_vect,y_train)\n",
    "y_pred = mnb.predict(X_test_vect)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<857x519 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 7403 stored elements in Compressed Sparse Row format>,\n",
       " <286x519 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 2372 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = TfidfVectorizer(stop_words=stopwords, min_df=0.005, max_df=0.99)\n",
    "vect.fit(X_train)\n",
    "X_train_vect = vect.transform(X_train)\n",
    "X_test_vect = vect.transform(X_test)\n",
    "\n",
    "X_train_vect, X_test_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   SMS Biasa       0.95      0.95      0.95       138\n",
      "SMS Operator       0.85      0.86      0.85        64\n",
      "    SMS Spam       0.86      0.85      0.85        84\n",
      "\n",
      "    accuracy                           0.90       286\n",
      "   macro avg       0.88      0.88      0.88       286\n",
      "weighted avg       0.90      0.90      0.90       286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_vect,y_train)\n",
    "y_pred = mnb.predict(X_test_vect)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(vect, mnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer',\n",
       "                 TfidfVectorizer(max_df=0.99, min_df=0.005,\n",
       "                                 stop_words=['yang', 'untuk', 'pada', 'ke',\n",
       "                                             'para', 'namun', 'menurut',\n",
       "                                             'antara', 'dia', 'dua', 'ia',\n",
       "                                             'seperti', 'jika', 'jika',\n",
       "                                             'sehingga', 'kembali', 'dan',\n",
       "                                             'tidak', 'ini', 'karena', 'kepada',\n",
       "                                             'oleh', 'saat', 'harus',\n",
       "                                             'sementara', 'setelah', 'belum',\n",
       "                                             'kami', 'sekitar', 'bagi', ...])),\n",
       "                ('multinomialnb', MultinomialNB())])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   SMS Biasa       0.95      0.95      0.95       138\n",
      "SMS Operator       0.85      0.86      0.85        64\n",
      "    SMS Spam       0.86      0.85      0.85        84\n",
      "\n",
      "    accuracy                           0.90       286\n",
      "   macro avg       0.88      0.88      0.88       286\n",
      "weighted avg       0.90      0.90      0.90       286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sms = [\n",
    "    'hai bro, apa kabar?',\n",
    "    'kuota 1 GB hanya 10.000 rupiah, dapatkan di aplikasi MyGSM',\n",
    "    'pesugihan halal, lipatgandakan uang anda bersama ki anu'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SMS Biasa', 'SMS Operator', 'SMS Biasa'], dtype='<U12')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(new_sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SMS Biasa', 'SMS Biasa', 'SMS Biasa'], dtype='<U12')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(corpus)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c524142758e41ff8da72ba142ad7f8c770fa04ceb078ed7556ced5f6ce4ae027"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
